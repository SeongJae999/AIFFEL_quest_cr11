{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번째 에포크 결과\n",
      "...sparse_categorical_accuracy: 0.9245\n",
      "...loss: 0.2591\n",
      "2번째 에포크 결과\n",
      "...sparse_categorical_accuracy: 0.9668\n",
      "...loss: 0.1143\n",
      "3번째 에포크 결과\n",
      "...sparse_categorical_accuracy: 0.9768\n",
      "...loss: 0.0814\n",
      "평가 결과:\n",
      "...val_sparse_categorical_accuracy: 0.9640\n",
      "...val_loss: 0.1363\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Input, Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# 모델 생성 함수\n",
    "def get_mnist_model():\n",
    "    model = Sequential([\n",
    "        layers.Flatten(input_shape=(28 * 28,)),  # 입력을 784 차원으로 설정\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# 모델 초기화\n",
    "model = get_mnist_model()\n",
    "loss_fn = SparseCategoricalCrossentropy()\n",
    "optimizer = RMSprop()\n",
    "metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "loss_tracking_metric = tf.keras.metrics.Mean()\n",
    "\n",
    "# 훈련 함수 정의\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "    \n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[metric.name] = metric.result()\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs['loss'] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "# 메트릭 초기화 함수\n",
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "# 데이터셋 준비\n",
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).batch(32)\n",
    "\n",
    "# 훈련 루프\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    reset_metrics()\n",
    "    for inputs_batch, targets_batch in training_dataset:\n",
    "        logs = train_step(inputs_batch, targets_batch)\n",
    "    print(f\"{epoch + 1}번째 에포크 결과\")\n",
    "    for key, value in logs.items():\n",
    "        print(f\"...{key}: {value:.4f}\")\n",
    "\n",
    "# 단계별 평가 루프\n",
    "@tf.function\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs['val_'+metric.name] = metric.result()\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs['val_loss'] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print('평가 결과:')\n",
    "for key, value in logs.items():\n",
    "    print(f'...{key}: {value:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.4483\n",
      "Epoch 2/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.1635\n",
      "Epoch 3/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.1300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2baafd9fd10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사용자 정의 훈련 스텝 구현\n",
    "loss_fn = SparseCategoricalCrossentropy()\n",
    "loss_tracker = tf.keras.metrics.Mean(name='loss')\n",
    "\n",
    "class CustomModel(tf.keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = loss_fn(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "        loss_tracker.update_state(loss)\n",
    "        return {'loss': loss_tracker.result()}\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker]\n",
    "\n",
    "# 모델 정의\n",
    "inputs = Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation='relu')(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation='softmax')(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "# 컴파일 및 훈련\n",
    "model.compile(optimizer=RMSprop())  \n",
    "model.fit(train_images, train_labels, epochs=3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - sparse_categorical_accuracy: 0.8628 - loss: 0.1000\n",
      "Epoch 2/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - sparse_categorical_accuracy: 0.9533 - loss: 0.1000\n",
      "Epoch 3/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - sparse_categorical_accuracy: 0.9609 - loss: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2baafd9ec60>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사용자 정의 훈련 스텝이 포함된 모델 클래스\n",
    "class CustomModel(tf.keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = self.compiled_loss(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "        self.compiled_metrics.update_state(targets, predictions)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "# 모델 정의\n",
    "inputs = Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation='relu')(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation='softmax')(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "# 컴파일 및 훈련\n",
    "model.compile(\n",
    "    optimizer=RMSprop(),  \n",
    "    loss=SparseCategoricalCrossentropy(),  # 손실 함수 설정\n",
    "    metrics=[SparseCategoricalAccuracy()]   # 정확도 메트릭 설정\n",
    ")\n",
    "\n",
    "# 훈련\n",
    "model.fit(train_images, train_labels, epochs=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "얕은 레이어 모델 훈련 및 평가\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">50,240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_7 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_41 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m50,240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_42 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,890</span> (198.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m50,890\u001b[0m (198.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,890</span> (198.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m50,890\u001b[0m (198.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 구조: None\n",
      "1번째 에포크 결과\n",
      "...sparse_categorical_accuracy: 0.9104\n",
      "...loss: 0.3178\n",
      "2번째 에포크 결과\n",
      "...sparse_categorical_accuracy: 0.9493\n",
      "...loss: 0.1756\n",
      "3번째 에포크 결과\n",
      "...sparse_categorical_accuracy: 0.9609\n",
      "...loss: 0.1363\n",
      "평가 결과:\n",
      "...val_sparse_categorical_accuracy: 0.9569\n",
      "...val_loss: 0.1486\n",
      "\n",
      "========================================\n",
      "\n",
      "깊은 레이어 모델 훈련 및 평가\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">200,960</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_8 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_43 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m200,960\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_44 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_45 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_46 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_47 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m330\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">244,522</span> (955.16 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m244,522\u001b[0m (955.16 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">244,522</span> (955.16 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m244,522\u001b[0m (955.16 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 구조: None\n",
      "1번째 에포크 결과\n",
      "...sparse_categorical_accuracy: 0.9256\n",
      "...loss: 0.2489\n",
      "2번째 에포크 결과\n",
      "...sparse_categorical_accuracy: 0.9693\n",
      "...loss: 0.1083\n",
      "3번째 에포크 결과\n",
      "...sparse_categorical_accuracy: 0.9792\n",
      "...loss: 0.0764\n",
      "평가 결과:\n",
      "...val_sparse_categorical_accuracy: 0.9605\n",
      "...val_loss: 0.1631\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 깊은 층과 얕은 층(layer)\n",
    "\n",
    "# 얕은 레이어 모델 생성 함수\n",
    "def get_shallow_mnist_model():\n",
    "    model = Sequential([\n",
    "        layers.Flatten(input_shape=(28 * 28,)),  # 입력을 784 차원으로 설정\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# 깊은 레이어 모델 생성 함수\n",
    "def get_deep_mnist_model():\n",
    "    model = Sequential([\n",
    "        layers.Flatten(input_shape=(28 * 28,)),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "# 데이터셋 준비\n",
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).batch(32)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels)).batch(32)\n",
    "\n",
    "# 공통 설정\n",
    "loss_fn = SparseCategoricalCrossentropy()\n",
    "optimizer = RMSprop()\n",
    "metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "loss_tracking_metric = tf.keras.metrics.Mean()\n",
    "\n",
    "# 메트릭 초기화 함수\n",
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()\n",
    "\n",
    "# 훈련 함수 정의\n",
    "def train_step(model, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "    \n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[metric.name] = metric.result()\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs['loss'] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "# 평가 함수 정의\n",
    "@tf.function\n",
    "def test_step(model, inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs['val_'+metric.name] = metric.result()\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs['val_loss'] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "# 모델 훈련 및 평가 루프\n",
    "def train_and_evaluate(model, optimizer, epochs=3):\n",
    "    print(f\"모델 구조: {model.summary()}\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        reset_metrics()\n",
    "        for inputs_batch, targets_batch in training_dataset:\n",
    "            logs = train_step(model, optimizer, inputs_batch, targets_batch)  # optimizer 전달\n",
    "        print(f\"{epoch + 1}번째 에포크 결과\")\n",
    "        for key, value in logs.items():\n",
    "            print(f\"...{key}: {value:.4f}\")\n",
    "\n",
    "    reset_metrics()\n",
    "    for inputs_batch, targets_batch in val_dataset:\n",
    "        logs = test_step(model, inputs_batch, targets_batch)\n",
    "    print('평가 결과:')\n",
    "    for key, value in logs.items():\n",
    "        print(f'...{key}: {value:.4f}')\n",
    "    print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "\n",
    "# 훈련 함수 정의 - optimizer를 추가 매개변수로 전달\n",
    "def train_step(model, optimizer, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "    \n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[metric.name] = metric.result()\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs['loss'] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "# 얕은 레이어 모델 훈련 및 평가\n",
    "print(\"얕은 레이어 모델 훈련 및 평가\")\n",
    "shallow_model = get_shallow_mnist_model()\n",
    "shallow_optimizer = RMSprop()  # 얕은 모델용 옵티마이저\n",
    "train_and_evaluate(shallow_model, shallow_optimizer)\n",
    "\n",
    "# 깊은 레이어 모델 훈련 및 평가\n",
    "print(\"깊은 레이어 모델 훈련 및 평가\")\n",
    "deep_model = get_deep_mnist_model()\n",
    "deep_optimizer = RMSprop()  # 깊은 모델용 옵티마이저\n",
    "train_and_evaluate(deep_model, deep_optimizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "+ 얕은 레이어 모델: 3 에포크 동안 훈련한 결과, 최종 훈련 정확도는 약 96.09%, 손실은 0.1363으로 나타났으며, 검증 정확도는 95.69%, 검증 손실은 0.1486\n",
    "\n",
    "+ 깊은 레이어 모델: 3 에포크 동안 훈련한 결과, 최종 훈련 정확도는 약 97.92%, 손실은 0.0764로 향상되었으며, 검증 정확도는 96.05%, 검증 손실은 0.1631\n",
    "\n",
    "## 요약: 깊은 레이어 모델이 얕은 레이어 모델보다 훈련 정확도와 손실에서 약간 더 좋은 성능을 보였으나, 검증 손실은 얕은 모델이 조금 더 낮게 나타남\n",
    "--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "높은 학습률로 훈련 및 평가\n",
      "학습률: 0.1\n",
      "1번째 에포크 결과\n",
      "...sparse_categorical_accuracy: 0.4953\n",
      "...loss: 2.8643\n",
      "2번째 에포크 결과\n",
      "...sparse_categorical_accuracy: 0.4195\n",
      "...loss: 1.5607\n",
      "3번째 에포크 결과\n",
      "...sparse_categorical_accuracy: 0.3789\n",
      "...loss: 1.6172\n",
      "평가 결과:\n",
      "...val_sparse_categorical_accuracy: 0.3653\n",
      "...val_loss: 1.5467\n",
      "\n",
      "========================================\n",
      "\n",
      "낮은 학습률로 훈련 및 평가\n",
      "학습률: 0.0001\n",
      "1번째 에포크 결과\n",
      "...sparse_categorical_accuracy: 0.8318\n",
      "...loss: 0.6626\n",
      "2번째 에포크 결과\n",
      "...sparse_categorical_accuracy: 0.9181\n",
      "...loss: 0.2852\n",
      "3번째 에포크 결과\n",
      "...sparse_categorical_accuracy: 0.9337\n",
      "...loss: 0.2320\n",
      "평가 결과:\n",
      "...val_sparse_categorical_accuracy: 0.9359\n",
      "...val_loss: 0.2219\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#학습률 차이(높음과 낮음)\n",
    "\n",
    "# 모델 생성 함수\n",
    "def get_mnist_model():\n",
    "    model = Sequential([\n",
    "        layers.Flatten(input_shape=(28 * 28,)),  # 입력을 784 차원으로 설정\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# 공통 설정\n",
    "loss_fn = SparseCategoricalCrossentropy()\n",
    "metrics = [tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "loss_tracking_metric = tf.keras.metrics.Mean()\n",
    "\n",
    "# 메트릭 초기화 함수\n",
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()\n",
    "\n",
    "# 훈련 함수 정의\n",
    "def train_step(model, optimizer, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "    \n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[metric.name] = metric.result()\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs['loss'] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "# 평가 함수 정의\n",
    "@tf.function\n",
    "def test_step(model, inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs['val_'+metric.name] = metric.result()\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs['val_loss'] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "# 모델 훈련 및 평가 루프\n",
    "def train_and_evaluate(learning_rate, epochs=3):\n",
    "    print(f\"학습률: {learning_rate}\")\n",
    "    model = get_mnist_model()\n",
    "    optimizer = RMSprop(learning_rate=learning_rate)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        reset_metrics()\n",
    "        for inputs_batch, targets_batch in training_dataset:\n",
    "            logs = train_step(model, optimizer, inputs_batch, targets_batch)\n",
    "        print(f\"{epoch + 1}번째 에포크 결과\")\n",
    "        for key, value in logs.items():\n",
    "            print(f\"...{key}: {value:.4f}\")\n",
    "\n",
    "    reset_metrics()\n",
    "    for inputs_batch, targets_batch in val_dataset:\n",
    "        logs = test_step(model, inputs_batch, targets_batch)\n",
    "    print('평가 결과:')\n",
    "    for key, value in logs.items():\n",
    "        print(f'...{key}: {value:.4f}')\n",
    "    print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "# 데이터셋 준비\n",
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).batch(32)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels)).batch(32)\n",
    "\n",
    "# 높은 학습률로 훈련 및 평가\n",
    "print(\"높은 학습률로 훈련 및 평가\")\n",
    "train_and_evaluate(learning_rate=0.1)\n",
    "\n",
    "# 낮은 학습률로 훈련 및 평가\n",
    "print(\"낮은 학습률로 훈련 및 평가\")\n",
    "train_and_evaluate(learning_rate=0.0001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------\n",
    "+ 높은 학습률 (0.1): 훈련 과정에서 불안정한 성능을 보였으며, 최종 훈련 정확도는 **37.89%**로 낮고, 손실은 1.6172로 높음. 검증 정확도는 36.53%, 검증 손실은 1.5467로 나타나 과적합이 제대로 이루어지지 않았음.\n",
    "\n",
    "+ 낮은 학습률 (0.0001): 훈련이 안정적으로 진행되었으며, 최종 훈련 정확도는 91.81%, 손실은 0.2852로 양호한 성능을 보임. 검증 정확도는 약 90% 이상으로 평가 결과도 좋았음.\n",
    "\n",
    "## 요약: 낮은 학습률이 더 안정적이며, 정확도와 손실 측면에서 높은 학습률보다 훨씬 우수한 성능을 보임.\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tanh 활성화 함수 모델 훈련 및 평가\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_54 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_55 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_56 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_11 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_54 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_55 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_56 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,386</span> (427.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m109,386\u001b[0m (427.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,386</span> (427.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m109,386\u001b[0m (427.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 구조: None\n",
      "1번째 에포크 결과\n",
      "...sparse_categorical_accuracy: 0.9182\n",
      "...loss: 0.2783\n",
      "2번째 에포크 결과\n",
      "...sparse_categorical_accuracy: 0.9591\n",
      "...loss: 0.1387\n",
      "3번째 에포크 결과\n",
      "...sparse_categorical_accuracy: 0.9720\n",
      "...loss: 0.0955\n",
      "평가 결과:\n",
      "...val_sparse_categorical_accuracy: 0.9636\n",
      "...val_loss: 0.1216\n",
      "\n",
      "========================================\n",
      "\n",
      "sigmoid 활성화 함수 모델 훈련 및 평가\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_12\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_57 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_12 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_57 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m100,480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_58 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_59 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,386</span> (427.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m109,386\u001b[0m (427.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">109,386</span> (427.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m109,386\u001b[0m (427.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 구조: None\n",
      "1번째 에포크 결과\n",
      "...sparse_categorical_accuracy: 0.8711\n",
      "...loss: 0.5034\n",
      "2번째 에포크 결과\n",
      "...sparse_categorical_accuracy: 0.9385\n",
      "...loss: 0.2078\n",
      "3번째 에포크 결과\n",
      "...sparse_categorical_accuracy: 0.9531\n",
      "...loss: 0.1551\n",
      "평가 결과:\n",
      "...val_sparse_categorical_accuracy: 0.9520\n",
      "...val_loss: 0.1578\n",
      "\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델 생성 함수 (기본 구조 유지)\n",
    "def get_mnist_model(activation='relu'):\n",
    "    model = Sequential([\n",
    "        layers.Flatten(input_shape=(28 * 28,)),  # 입력을 784 차원으로 설정\n",
    "        layers.Dense(128, activation=activation),\n",
    "        layers.Dense(64, activation=activation),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# 데이터 로드 및 전처리\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "# 데이터셋 준비\n",
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).batch(32)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels)).batch(32)\n",
    "\n",
    "# 공통 설정\n",
    "loss_fn = SparseCategoricalCrossentropy()\n",
    "metrics = [SparseCategoricalAccuracy()]\n",
    "loss_tracking_metric = tf.keras.metrics.Mean()\n",
    "\n",
    "# 메트릭 초기화 함수\n",
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()\n",
    "\n",
    "# 훈련 함수 정의\n",
    "def train_step(model, optimizer, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "    \n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[metric.name] = metric.result()\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs['loss'] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "# 평가 함수 정의\n",
    "@tf.function\n",
    "def test_step(model, inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs['val_' + metric.name] = metric.result()\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs['val_loss'] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "# 모델 훈련 및 평가 루프\n",
    "def train_and_evaluate(model, optimizer, epochs=3):\n",
    "    print(f\"모델 구조: {model.summary()}\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        reset_metrics()\n",
    "        for inputs_batch, targets_batch in training_dataset:\n",
    "            logs = train_step(model, optimizer, inputs_batch, targets_batch)\n",
    "        print(f\"{epoch + 1}번째 에포크 결과\")\n",
    "        for key, value in logs.items():\n",
    "            print(f\"...{key}: {value:.4f}\")\n",
    "\n",
    "    reset_metrics()\n",
    "    for inputs_batch, targets_batch in val_dataset:\n",
    "        logs = test_step(model, inputs_batch, targets_batch)\n",
    "    print('평가 결과:')\n",
    "    for key, value in logs.items():\n",
    "        print(f'...{key}: {value:.4f}')\n",
    "    print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "\n",
    "# tanh 활성화 함수 모델 훈련 및 평가\n",
    "print(\"tanh 활성화 함수 모델 훈련 및 평가\")\n",
    "tanh_model = get_mnist_model(activation='tanh')\n",
    "tanh_optimizer = RMSprop()\n",
    "train_and_evaluate(tanh_model, tanh_optimizer)\n",
    "\n",
    "# sigmoid 활성화 함수 모델 훈련 및 평가\n",
    "print(\"sigmoid 활성화 함수 모델 훈련 및 평가\")\n",
    "sigmoid_model = get_mnist_model(activation='sigmoid')\n",
    "sigmoid_optimizer = RMSprop()\n",
    "train_and_evaluate(sigmoid_model, sigmoid_optimizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "### tanh 활성화 함수 모델:\n",
    "\n",
    "+ 최종 훈련 정확도: 97.20%\n",
    "+ 최종 훈련 손실: 0.0955\n",
    "+ 검증 정확도: 96.36%\n",
    "+ 검증 손실: 0.1216\n",
    "--------------\n",
    "\n",
    "### sigmoid 활성화 함수 모델:\n",
    "\n",
    "+ 최종 훈련 정확도: 95.31%\n",
    "+ 최종 훈련 손실: 0.1551\n",
    "+ 검증 정확도: 95.20%\n",
    "+ 검증 손실: 0.1578\n",
    "--------------\n",
    "요약: tanh 활성화 함수를 사용한 모델이 sigmoid를 사용한 모델보다 훈련 및 검증 정확도와 손실에서 더 우수한 성능을 보임. 기울기가 tanh가 더 높기 때문.\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "회고\n",
    "============\n",
    "# 점점 속도가 빨라진다.\n",
    "## 자꾸 해보니 모델 구조가 조금씩 눈에 익어간다.\n",
    "### 모델이 뭘 학습하고 뱉어내는지 감만 잡힌다.\n",
    "-----------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
